{
 "metadata": {
  "name": "",
  "signature": "sha256:2938865d720524991d78a94e13d09334e706205be47cb368b53db24f12f79391"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Load training data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import menpo.io as mio\n",
      "from menpo.landmark import labeller, ibug_face_66\n",
      "from menpofast.utils import convert_from_menpo\n",
      "\n",
      "group = 'ibug_face_66'\n",
      "\n",
      "training_images = []\n",
      "for i in mio.import_images('/Users/joan/PhD/DataBases/faces/lfpw/trainset/',\n",
      "                           verbose=True, max_images=None):\n",
      "    \n",
      "    # convert the image from menpo Image to menpofast Image (channels at front)\n",
      "    i = convert_from_menpo(i)\n",
      "    \n",
      "    labeller(i, 'PTS', eval(group))\n",
      "    i.crop_to_landmarks_proportion_inplace(0.5, group=group)\n",
      "    i = i.rescale_landmarks_to_diagonal_range(200, group=group)\n",
      "    \n",
      "    if i.n_channels == 3:\n",
      "        i = i.as_greyscale(mode='average')\n",
      "    training_images.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in mio.import_images('/Users/joan/PhD/DataBases/faces/helen/trainset/',\n",
      "                           verbose=True, max_images=None):\n",
      "    \n",
      "    # convert the image from menpo Image to menpofast Image (channels at front)\n",
      "    i = convert_from_menpo(i)\n",
      "    \n",
      "    labeller(i, 'PTS', eval(group))\n",
      "    i.crop_to_landmarks_proportion_inplace(0.5, group=group)\n",
      "    i = i.rescale_landmarks_to_diagonal_range(200, group=group)\n",
      "    \n",
      "    if i.n_channels == 3:\n",
      "        i = i.as_greyscale(mode='average')\n",
      "    training_images.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in mio.import_images('/Users/joan/PhD/DataBases/faces/ibug/',\n",
      "                           verbose=True, max_images=None):\n",
      "    \n",
      "    # convert the image from menpo Image to menpofast Image (channels at front)\n",
      "    i = convert_from_menpo(i)\n",
      "    \n",
      "    labeller(i, 'PTS', eval(group))\n",
      "    i.crop_to_landmarks_proportion_inplace(0.5, group=group)\n",
      "    i = i.rescale_landmarks_to_diagonal_range(200, group=group)\n",
      "    \n",
      "    if i.n_channels == 3:\n",
      "        i = i.as_greyscale(mode='average')\n",
      "    training_images.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpo.visualize import visualize_images\n",
      "\n",
      "visualize_images(training_images)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Active Appearance Models"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Build"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpofast.feature import no_op, fast_dsift, fast_daisy\n",
      "from alabortcvpr2015.aam import PartsAAMBuilder\n",
      "\n",
      "aam = PartsAAMBuilder(parts_shape=(17, 17),\n",
      "                 features=fast_dsift,\n",
      "                 diagonal=100,\n",
      "                 normalize_parts=False,\n",
      "                 scales=(1, .5),\n",
      "                 max_shape_components=25,\n",
      "                 max_appearance_components=250).build(training_images,\n",
      "                                                      group=group,\n",
      "                                                      verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpofast.image import Image\n",
      "\n",
      "Image(aam.appearance_models[0].mean().pixels[37, 0]).view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Save"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from alabortcvpr2015.utils import pickle_dump\n",
      "\n",
      "pickle_dump(aam, '/Users/joan/PhD/Models/aam_lfpw_fast_dsift')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}