{
 "metadata": {
  "name": "",
  "signature": "sha256:ce3863724c7c7b558feb06304587eaa445b87637eb25b0ebd0d85ae499f04de2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Load training data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import menpo.io as mio\n",
      "from menpo.landmark import labeller, ibug_face_66\n",
      "from menpofast.utils import convert_from_menpo\n",
      "\n",
      "group = 'ibug_face_66'\n",
      "\n",
      "training_images = []\n",
      "for i in mio.import_images('/Users/joan/PhD/DataBases/faces/lfpw/trainset/',\n",
      "                           verbose=True, max_images=None):\n",
      "    \n",
      "    # convert the image from menpo Image to menpofast Image (channels at front)\n",
      "    i = convert_from_menpo(i)\n",
      "    \n",
      "    labeller(i, 'PTS', eval(group))\n",
      "    i.crop_to_landmarks_proportion_inplace(0.5, group=group)\n",
      "    i = i.rescale_landmarks_to_diagonal_range(200, group=group)\n",
      "    \n",
      "    if i.n_channels == 3:\n",
      "        i = i.as_greyscale(mode='average')\n",
      "    training_images.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in mio.import_images('/Users/joan/PhD/DataBases/faces/helen/trainset/',\n",
      "                           verbose=True, max_images=None):\n",
      "    \n",
      "    # convert the image from menpo Image to menpofast Image (channels at front)\n",
      "    i = convert_from_menpo(i)\n",
      "    \n",
      "    labeller(i, 'PTS', eval(group))\n",
      "    i.crop_to_landmarks_proportion_inplace(0.5, group=group)\n",
      "    i = i.rescale_landmarks_to_diagonal_range(200, group=group)\n",
      "    \n",
      "    if i.n_channels == 3:\n",
      "        i = i.as_greyscale(mode='average')\n",
      "    training_images.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in mio.import_images('/Users/joan/PhD/DataBases/faces/ibug/',\n",
      "                           verbose=True, max_images=None):\n",
      "    \n",
      "    # convert the image from menpo Image to menpofast Image (channels at front)\n",
      "    i = convert_from_menpo(i)\n",
      "    \n",
      "    labeller(i, 'PTS', eval(group))\n",
      "    i.crop_to_landmarks_proportion_inplace(0.5, group=group)\n",
      "    i = i.rescale_landmarks_to_diagonal_range(200, group=group)\n",
      "    \n",
      "    if i.n_channels == 3:\n",
      "        i = i.as_greyscale(mode='average')\n",
      "    training_images.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpo.visualize import visualize_images\n",
      "\n",
      "visualize_images(training_images)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Constrained Local Models"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Build"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from menpofast.feature import no_op, fast_dsift, fast_daisy\n",
      "from alabortcvpr2015.clm import CLMBuilder\n",
      "from alabortcvpr2015.clm.classifier import MCF\n",
      "\n",
      "offsets = np.meshgrid(range(-0, 1, 1), range(-0, 1, 1))\n",
      "offsets = np.asarray([offsets[0].flatten(), offsets[1].flatten()]).T \n",
      "\n",
      "clm = CLMBuilder(parts_shape=(17, 17),\n",
      "                 features=fast_dsift,\n",
      "                 diagonal=100,\n",
      "                 classifier=MCF,\n",
      "                 normalize_parts=False,\n",
      "                 covariance=3,\n",
      "                 scales=(1, .5),\n",
      "                 offsets=offsets).build(training_images, \n",
      "                                        group=group, \n",
      "                                        verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clm.parts_filters()[0][37].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Save"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from alabortcvpr2015.utils import pickle_dump\n",
      "\n",
      "pickle_dump(clm, '/Users/joan/PhD/Models/clm_lfpw_fast_dsift')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}